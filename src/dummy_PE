/*
 * PE.cpp
 *
 *  Created on: Mar 4, 2010
 *      Author: Ardavan
 */

#include "PE.h"
using namespace std;

PE::PE()
{
	// TODO Auto-generated constructor stub

}

PE::PE(int row, int col,  double * row_write_bus, double * row_read_bus, double * col_write_bus, double * col_read_bus)
{
	// TODO



	My_Row= row;
	My_Column= col;

	Scratch_Regs_Curr=(double *) malloc( sizeof(double) * (Scratch_Size));
	Scratch_Regs_Next=(double *) malloc( sizeof(double) * (Scratch_Size));

	Read_My_Col_Bus= col_read_bus;
	Read_My_Row_Bus= row_read_bus;

	Write_My_Col_Bus= col_write_bus;
	Write_My_Row_Bus= row_write_bus;

	//cout<< "end of PE const"<<endl;
}

PE::~PE()
{
	// TODO Auto-generated destructor stub
}


int PE::Cycle(){

	int i;
	for (i=0; i<Scratch_Size; i++)
		Scratch_Regs_Curr[i]=Scratch_Regs_Next[i];

	ALU.Cycle();
	//Local_Mem.Cycle();

	Counter_Curr=Counter_Next;
//	Address_Curr=Address_Next;

	Write_My_Col_Reg_Curr=Write_My_Col_Reg_Next;
	Write_My_Row_Reg_Curr=Write_My_Row_Reg_Next;

}



int PE::Intialize_Local_Mem( double ** Input_matrix, int row_number, int column_number){

	Local_Mem.Initialize_Register_File(My_Row, My_Column, Input_matrix,row_number, column_number);
	return 0;

}

int PE::Flush_Local_Mem( double **& Input_matrix, int row_number, int column_number, int offset){

	Local_Mem.Flush_Register_File(Input_matrix,row_number, column_number, offset);
	return 0;

}

int PE::Dump_Regs(){

	int i;
	cout<<"PE("<<My_Row<<","<<My_Column<<"):"<<endl;

	for (i=0; i < Scratch_Size ;i++)
		cout << "Scratch["<<i<<"]"<<"="<<Scratch_Regs_Curr[i]<<endl;

	// What I am about to BC
	cout<<"Write_My_Col_Reg_Curr="<<Write_My_Col_Reg_Curr<<endl;
	cout<<"Write_My_Row_Reg_Curr="<<Write_My_Row_Reg_Curr<<endl;

	//What I see
	cout<<"Read_My_Col_Bus="<<*Read_My_Col_Bus<<endl;
	cout<<"Read_My_Row_Bus="<<*Read_My_Row_Bus<<endl;


	cout <<"Local_Mem_Address="<<Local_Mem_Address<<endl;
	cout<<"Accumulator="<<ALU.Return_ACC()<<endl;
	return 0 ;

}



int PE::Dump_ALU_Pipeline(ALU_op operation_type){


	cout<<"PE("<<My_Row<<","<<My_Column<<")"<<endl;
	cout<<"Dumping ALU_Pipeline ..,"<<endl;
	ALU.Dump_Pipeline(operation_type);


	}



int PE::Generate_Address_Signals(int Global_index, int Trsm_index, int Iter_Counter, int Latency_Counter,
								LAPU_Function routine,int LAPU_Current_State, int State_Start){

 Local_Mem_Address=-1;
// If I access memory with -1 Address I have had a Bug so it is good bug checcking scheme
	switch (routine){

		case LAPU_Cholesky:

			switch (LAPU_Current_State){

				case 1: // Initial

					//retrieve data from local memory
					//it should be the (0,0) PE  and iteration is automatically 0;
					if ((My_Row==My_Column) && (Iter_Counter==0))  // since it is the First Retrieve

						{
						Local_Mem_Address= Global_index * (Kernel_Size / LAPU_Size)+ Global_index;// + iter_Counter ;

						// find the place of the diagonal element in the diagonal PE
						}

					// put it on the bus

					// Two options one we just have many different signals that are PE variables and we set them
					// in the beginning of each execution  (this means that I call the function from LAPU level)

					// Second I just work function based which I do not know how it simplifies the things here.
					// Design Choice: Function Based function Calls
					else Local_Mem_Address=-1;



				break;

				case 2:  // Feed_Sqrt

					//PEs, Are Waiting for the Bus to pass the data to Sqrt;
					//Do nothing
					Local_Mem_Address=-2;


				break;

				case 3: //Cho_Inv_Sqrt

					//PEs Are Waiting for the Sqrt to be computed
					Local_Mem_Address=-3;

				break;


				case 4: // Chol_BC_InvSqrt

					//PEs are waiting for Sqrt to come back

					Local_Mem_Address=-4;

				break;

				case 5:  // Chol_Multiply

					// If I am in the iteration_Numbers row or column I have to read from my Bus  and perform Multiply;
					// on my Local Data
					// If iteration is 0 I have to fetch it, else I have already fetched it for Rank_1 Update before


					if ((Iter_Counter==0)&& (( My_Row==0) || (My_Column==0)))

						Local_Mem_Address= Global_index * (Kernel_Size / LAPU_Size)+ Global_index;
					// If I am the diagonal PE I have to save inv_Sqrt to a scratchpad register;
					//I am not

					// probably put the result of the multiply on the bus in the last cycle
					else
						Local_Mem_Address=-5;

				break;


				case 6: //  Chol_BC_Mul

					//PEs are just sending what they multiply to receivers

					// This PEs will save the produced data into local memory
					if ( (My_Column==Iter_Counter) || (My_Row==Iter_Counter))
						Local_Mem_Address= Global_index * (Kernel_Size / LAPU_Size)+ Global_index;

					else //PEs are waiting to be brightened up by new data :D
						Local_Mem_Address=-6;


				break;


				case 7: // Chol_Rank1_Update;


					// Those PEs that are supposed to be aupdated
					if ( (My_Column>Iter_Counter) && (My_Row>Iter_Counter)){

						Local_Mem_Address=Global_index * (Kernel_Size / LAPU_Size)+ Global_index;


					}

					else  // Other PEs are dead
						Local_Mem_Address=-7;
				break;


				case 8: // End

					Local_Mem_Address=-8;
					// Store them All so
					Local_Mem_Address=Global_index * (Kernel_Size / LAPU_Size)+ Global_index;

				break;

			}





			break; // Final decision: Just fetch all from local register file in the initial state
					//and the rest of operations do not work with Local Stare
					// in the End State Store the data

		case LAPU_Trsm:

			switch (LAPU_Current_State){

				case 1:  //Initial
					// Just move the Data to the Bus if you are Diagonal PE
					// All other PEs Retrieve the Data to Accumulator of yourself
					//prepare for Multiplication
					Local_Mem_Address=Global_index*(Kernel_Size / LAPU_Size)+
							Global_index+ Trsm_index ;



				break;

				case 2:  //BC_Inv_Sqrt

					Local_Mem_Address=-2; //

				break;

				case 3:  //Multiply

					// If My_Row=Iteration_counter perform Multiply
					// in the last cycle If My_Row==Iteration_counter then Send the result on the Column bus
					//and save it to local store too

					Local_Mem_Address=  Global_index * (Kernel_Size/LAPU_Size) + (Trsm_index);
					// else do nothing

					//If Iter_counter==My_Column and My_Row >=Iter_counter then send the "cholesky column" to the row bus


				break;

				case 4:  //BC_Multiply


					//Do nothing

					Local_Mem_Address=-4;

				break;

				case 5:  //Partial_Rank_1

					Local_Mem_Address=-5;

					//everything is in the the scratch_pad memory;
					// Diagonal PE send the data on the row bus for possible next broadcast

					// if 1st clock cycle:
					// start MAc operations
					//if I am a diagonal PE get the data from column_bus and put it on the row_bus

					//if 2nd clock cycle:
					// If my column==iteration_Counter then save the row bus into local memory
					Local_Mem_Address= (Trsm_index)* (Kernel_Size/LAPU_Size)  +  Global_index;


					//if any other time just do continue MAc operation;


				break;


				case 6:  //End


				break;


			}


		case LAPU_Rank_Update:

			switch(LAPU_Current_State){

				case 1: // Initial it takes two cycles for loading the data from local store and putting it on column or row buses

					// in first cycle
					// ALL Diagonal PEs read from memory the  columns supposed to be BCasted

  // Iter_Counter must be zero
						if (My_Column==My_Row)
								Local_Mem_Address= (Iter_Counter/ LAPU_Size) * (Kernel_Size/LAPU_Size)+Trsm_index;


					//in second
					//Prepare to BC the first column and first row  (Diagonal PE does the row fetch now)



				break;

				case 2: // Gemm_Pre_Fetch


						if (My_Row==0)
							Local_Mem_Address=(Global_index)*(Kernel_Size/LAPU_Size) + Iter_Counter/LAPU_Size;

						else if (My_Column==0)
							Local_Mem_Address=(Iter_Counter/LAPU_Size) * Kernel_Size/LAPU_Size + Trsm_index;

				break;
				case 3: // BC

					// during first BC: load the target matrix into the accumulator
					Local_Mem_Address=Global_index*(Kernel_Size/LAPU_Size)+Global_index+Trsm_index;

				break;

				case 4: // MAC_and_BC

					//problem with the diagonal PEs they need 2 cycles to read data
					// since they have to put data both on column and row bus
					//Solution:
					// But N+1st diagonal PE pre-fetches the data into its scratch pad memory of itself,
					//when the Nth diagonal PEs are fetching their data to BC
					if (My_Row==(Iter_Counter%LAPU_Size))
						Local_Mem_Address=(Global_index)*(Kernel_Size/LAPU_Size) + Iter_Counter/LAPU_Size;

					else if (My_Column==(Iter_Counter%LAPU_Size))
						Local_Mem_Address=(Iter_Counter/LAPU_Size) * Kernel_Size/LAPU_Size + Trsm_index;


					if (Iter_Counter % LAPU_Size==0) // Prefetch for all diagonal PEs staring from 1,1
						if (My_Column==My_Row)
								Local_Mem_Address= (Iter_Counter/ LAPU_Size) * (Kernel_Size/LAPU_Size)+Trsm_index;

					if (Iter_Counter % LAPU_Size==(LAPU_Size -1)) // Prefetch for 0,0 PE
						if ((My_Column==My_Row) && (My_Column==0))
							Local_Mem_Address= ((Iter_Counter/ LAPU_Size)+1) * (Kernel_Size/LAPU_Size)+Trsm_index;

					//	Local_Mem_Address

				break;

				case 5: // MAC
					// Nothing left to do;
					Local_Mem_Address=-4;
				break;

				case 6: // End
					// Write the matrix back into the Local_Store
					Local_Mem_Address=Global_index*(Kernel_Size/LAPU_Size)+Global_index+Trsm_index;

				break;


			}


		break;

	}



	return Local_Mem_Address;



}
//int PE::


//TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO
//TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO
//TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO
//TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO
//TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO
//TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO
//TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO
//TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO
//TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO
//TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO




int PE::Execute				(int Global_index, int Trsm_index, int Iter_Counter, int Latency_Counter,
							LAPU_Function routine,int LAPU_Current_State, int State_Start){


 Local_Mem_Address=-1;
	// If I access memory with -1 Address I have had a Bug so it is good bug checcking scheme



		 switch (routine){

			case LAPU_Cholesky:

				if ((My_Row==My_Column) && (My_Row==0)) cout<< "Exectuing CHOLESKY ..."<<endl;
				switch (LAPU_Current_State){

					case 0: // Initial

						//retrieve data from local memory
						//it should be the (0,0) PE  and iteration is automatically 0;
						// If iteration is 0
						//if (Global_Index==0 "I have not brought it here before to update" && iteration==0 "'it is not update within cholesky")
						//I have to fetch my local data,else I have already fetched it for Rank_1 Update before
						// Actually other than the first Cholesky data is always in scratch pad memory but I do not mention it here.


						//if (Global_Index==0)
						//if ((My_Row==My_Column) && (Iter_Counter==0))  // since it is the First Retrieve

						//	{
							Local_Mem_Address= Global_index * (Kernel_Size / LAPU_Size)+ Global_index;
							// find the place of the diagonal element in the diagonal PE

							// put it on the bus

						//	}

							if (Global_index==0) // write to Scratch_Pad since we had no Rank-K update
								Scratch_Regs_Next[0]=Local_Mem.Reg_Read(Local_Mem_Address);

							if ((My_Row==My_Column) && (My_Row==Iter_Counter))
								Write_My_Row_Reg_Next=Local_Mem.Reg_Read(Local_Mem_Address);

						// If iteration is 0 (Global_Index==0 "I have brought it here to update" && iteration==0) I have to fetch my local data, else I have already fetched it for Rank_1 Update before



						// TODO I put it on the Row bus

						//else Local_Mem_Address=-1;



					break;

					case 1:  // Feed_Sqrt





						if ((My_Row==My_Column) && (My_Row==Iter_Counter)){
								*Write_My_Row_Bus=Write_My_Row_Reg_Curr;
								//cout<<"I wrote on the Bus this"<< *Write_My_Row_Bus<<endl;
						}

						//PEs, Are Waiting for the Bus to pass the data to Sqrt;
						//Do nothing
						//Local_Mem_Address=-2;


					break;

					case 2: //Chol_Inv_Sqrt

						//PEs Are Waiting for the Sqrt to be computed
						Local_Mem_Address=-3;

					break;


					case 3: // Chol_BC_InvSqrt

						//PEs are waiting for Sqrt to come back

						Local_Mem_Address=-4;

					break;

					case 4:  // Chol_Multiply

						// If I am in the iteration_Numbers row or column I have to read from my Bus  and perform Multiply;
						// on my Local Data
						// If iteration is 0 and Global_index=0 I have to fetch it, else I have already fetched it for Rank_1 Update before

						// Lets do the fetching first in intialization if needed and get rid of this complexity


						// If I am the diagonal PE I have to save inv_Sqrt to a scratchpad register;

						if ((My_Row==Iter_Counter) && (Latency_Counter==0)) // Saving one BroadCast clock in Trsm :D
							Scratch_Regs_Next[1]=*Read_My_Row_Bus;

						if ( ( (My_Row==Iter_Counter)&&(My_Column>=My_Row) )  || ( (My_Column==Iter_Counter) && (My_Row>=My_Column) )   ){

							if (Latency_Counter<(Multiplication_Latency-1)){
								if (My_Row==Iter_Counter)
									ALU.Execute_Mul(*Read_My_Row_Bus,Scratch_Regs_Curr[0]);
								else
									ALU.Execute_Mul(*Read_My_Col_Bus,Scratch_Regs_Curr[0]);
							}

							else{

								Scratch_Regs_Next[0]=ALU.Execute_Mul(*Read_My_Row_Bus,Scratch_Regs_Curr[0]);

								if (My_Row==Iter_Counter)
									Write_My_Col_Reg_Next=Scratch_Regs_Next[0];
								if (My_Column==Iter_Counter)
									Write_My_Row_Reg_Next=Scratch_Regs_Next[0];

							}
						}

							//TODO  I do not care about what else I feed to it in other cycles right now



						// probably put the result of the multiply on the bus in the last cycle


					break;


					case 5: //  Chol_BC_Mul

						//PEs are just sending what they multiply to receivers


						if ((My_Column==Iter_Counter)  && (My_Column!=My_Row))
							*Write_My_Row_Bus=Write_My_Row_Reg_Curr;


						if	((My_Row==Iter_Counter)&& (My_Column!=My_Row))
							*Write_My_Col_Bus=Write_My_Col_Reg_Curr;



							//PEs are waiting to be brightened up by new data :D



					break;


					case 6: // Chol_Rank1_Update;


						// Those PEs that are supposed to be updated
						if ( (My_Column>Iter_Counter) && (My_Row>Iter_Counter)){

							if (Latency_Counter<(FMA_Latency-1)){
								ALU.Execute_MAD(*Read_My_Col_Bus, (-1)*(*Read_My_Row_Bus), Scratch_Regs_Curr[0]);

							}
							else {

								Scratch_Regs_Next[0]=ALU.Execute_MAD(*Read_My_Col_Bus, (-1.0)*(*Read_My_Row_Bus), Scratch_Regs_Curr[0]);
								if ((My_Column==(Iter_Counter+1))  && (My_Row==(Iter_Counter+1)))
									Write_My_Row_Reg_Next=Scratch_Regs_Next[0];
							}

						}


					break;


					case 7: // End

						Local_Mem_Address=-8;
						// Store them All so


						Local_Mem_Address=Global_index * (Kernel_Size / LAPU_Size)+ Global_index;
						cout<<"PE("<<My_Row<<","<<My_Column<<") Regiters["<<Local_Mem_Address<<"]="<<Scratch_Regs_Curr[0];


						Local_Mem.Reg_Write(Local_Mem_Address,Scratch_Regs_Curr[0]);
					break;

				}





				break; // Final decision: Just fetch all from local register file in the initial state
						//and the rest of operations do not work with Local Stare
						// in the End State Store the data

			case LAPU_Trsm:
				if ((My_Row==My_Column) && (My_Row==0)) cout<< "Exectuing TRSM ..."<<endl;
				switch (LAPU_Current_State){

					case 0:  //Initial
						// Just move the Data to the Bus if you are Diagonal PE
						// All other PEs Retrieve the Data to Accumulator of yourself
						//prepare for Multiplication





						//Local_Mem_Address=Global_index*(Kernel_Size / LAPU_Size)+Trsm_index ;

						Local_Mem_Address= (Trsm_index)* (Kernel_Size/LAPU_Size)  +  Global_index;
						//if ((My_Row==0)&&(My_Column==0))
						//	  Dump_Regs();


						//TODO
						//TODO
						//TODO if global_index==0
						//it is loaded by Rank_K Update already
						if (Global_index==0)
						Scratch_Regs_Next[2]=Local_Mem.Reg_Read(Local_Mem_Address);
						// Bring the target Vectors into Scratch_Pad memory
						// you have the inv_Sqrts in yourslev so no need to BC_Inv_Sqrt


					break;

					case 1:  //BC_Inv_Sqrt

						Local_Mem_Address=-2; //

					break;

					case 2:  //Multiply

						// If My_Row=Iteration_counter perform Multiply
						// in the last cycle If My_Row==Iteration_counter then Send the result on the Column bus
						//and save it to local store too

						if (My_Row==Iter_Counter)
							if (Latency_Counter<(Multiplication_Latency-1))
								ALU.Execute_Mul(Scratch_Regs_Curr[2],Scratch_Regs_Curr[1]);

							else{

									Scratch_Regs_Next[2]=ALU.Execute_Mul(Scratch_Regs_Curr[2],Scratch_Regs_Curr[1]);

										Write_My_Col_Reg_Next=Scratch_Regs_Next[2];

								}

						if ((My_Column == Iter_Counter) && (My_Row> Iter_Counter))
							if (Latency_Counter==(Multiplication_Latency-1))
								Write_My_Row_Reg_Next=Scratch_Regs_Curr[0];



						//If Iter_counter==My_Column and My_Row >=Iter_counter then send the "cholesky column" to the row bus


					break;

					case 3:  //BC_Multiply


						if (My_Row==Iter_Counter)
							*Write_My_Col_Bus=Write_My_Col_Reg_Curr;

						if ((My_Column == Iter_Counter) && (My_Row> Iter_Counter))
							*Write_My_Row_Bus=Write_My_Row_Reg_Curr;



					break;

					case 4:  //Partial_Rank_1 //Assumption MAC delay is at least 2 clocks

						Local_Mem_Address=-5;

						//everything is in the the scratch_pad memory; or received from buses

						//Computation Part
						if (My_Row>Iter_Counter){

							if (Latency_Counter<(FMA_Latency-1)){
								ALU.Execute_MAD(*Read_My_Col_Bus, (-1)*(*Read_My_Row_Bus), Scratch_Regs_Curr[2]);

							}
							else {

								Scratch_Regs_Next[2]=ALU.Execute_MAD(*Read_My_Col_Bus, (-1.0)*(*Read_My_Row_Bus), Scratch_Regs_Curr[2]);

							}

						}

						// Communication

						if (Latency_Counter==0)
							if (My_Row==My_Column)
								*Write_My_Row_Bus=*Read_My_Col_Bus; // TODO I assumed I can read and write in 1+1 cycles (By_Passed the Write Register)

						if (Latency_Counter==1)
							if  (My_Column==Iter_Counter){
								//Local_Mem_Address= (Trsm_index)* (Kernel_Size/LAPU_Size)  +  Global_index;
								Local_Mem_Address=Global_index*(Kernel_Size / LAPU_Size)+Trsm_index ;

								Local_Mem.Reg_Write(Local_Mem_Address, *Read_My_Row_Bus);
							}


						// if 1st clock cycle:
						// start MAc operations
						//if I am a diagonal PE get the data from column_bus and put it on the row_bus

						//if 2nd clock cycle:
						// If my column==iteration_Counter then save the row bus into local memory



						//if any other time just do continue MAc operation;


					break;



					case 5: //Trans

						if (Latency_Counter==0)
							if (My_Row==My_Column)
								*Write_My_Row_Bus=*Read_My_Col_Bus; // TODO I assumed I can read and write in 1+1 cycles (By_Passed the Write Register)

						if (Latency_Counter==1)
							if  (My_Column==Iter_Counter){
								//Local_Mem_Address= (Trsm_index)* (Kernel_Size/LAPU_Size)  +  Global_index;
								Local_Mem_Address=Global_index*(Kernel_Size / LAPU_Size)+Trsm_index ;

								Local_Mem.Reg_Write(Local_Mem_Address, *Read_My_Row_Bus);
							}
						break;


					case 6:  //End



						//Local_Mem_Address=Global_index*(Kernel_Size / LAPU_Size)+Trsm_index ;
						Local_Mem_Address= (Trsm_index)* (Kernel_Size/LAPU_Size)  +  Global_index;


						Local_Mem.Reg_Write(Local_Mem_Address,Scratch_Regs_Curr[2]);


					break;


				}
				//Dump_Regs();

			break;
			case LAPU_Rank_Update:

				switch(LAPU_Current_State){

					case 0: // Initial it takes two cycles for loading the data from local store and putting it on column or row buses


							// load the target matrix into the accumulator
							Local_Mem_Address=Global_index*(Kernel_Size/LAPU_Size)+Trsm_index;
							//Scratch_Regs_Next[0]=Local_Mem.Reg_Read(Local_Mem_Address);
							//loading accumulator
							ALU.Load_Accumulator(Local_Mem.Reg_Read(Local_Mem_Address));


					break;

					case 1: //Pre_Fetch


						// in first cycle  Prefetch PE(0,0)
						//  PE(0,0) read from memory the  column supposed to be BCasted

						if (Latency_Counter==0){

							if (  (My_Row==0) && (My_Column==My_Row) ){
									Local_Mem_Address= ( (Iter_Counter+2)/ LAPU_Size) * (Kernel_Size/LAPU_Size)+Trsm_index;
									Write_My_Row_Reg_Next=Local_Mem.Reg_Read(Local_Mem_Address);
								}
						}


						//in second Cycle
						//1: Pre_Fetch  PE(1,1)
						//2: Prepare to BC the Column 0 and Row 0  (Diagonal PE does the row fetch now)

						else{ // Latency_Counter==1


							// Prefetch PE(1,1)
							if ( (My_Row==1) && (My_Column==My_Row) ){
									Local_Mem_Address= ((Iter_Counter+2)/ LAPU_Size) * (Kernel_Size/LAPU_Size)+Trsm_index;
									Write_My_Row_Reg_Next=Local_Mem.Reg_Read(Local_Mem_Address);
								}


							//Prepare to BC the 0th column and 0th row  (Diagonal PE does the row fetch now)
							if (My_Row==0){
								Local_Mem_Address=(Global_index)*(Kernel_Size/LAPU_Size) + (Iter_Counter+1)/LAPU_Size;
								Write_My_Col_Reg_Next=Local_Mem.Reg_Read(Local_Mem_Address);
							}
							else if (My_Column==0){
								Local_Mem_Address=((Iter_Counter+1)/LAPU_Size) * Kernel_Size/LAPU_Size + Trsm_index;
								Write_My_Row_Reg_Next=Local_Mem.Reg_Read(Local_Mem_Address);
							}
						}


					break;

					case 2: // BC

						//Iteration_counter=0;

						//Iteration_Counter Starting to count from now on
						//-> BC is the base: we are Broad_Casting (Iteration_Counter)th Row and Column


						//1- Pre_Fetch PE(2,2)
						//2-Prepare to BC the Column 1 and Row 1  (Diagonal PE does the row fetch now)
						//3- Drive the Bus for Row 0 and  Column 0



						// Pre_Fetch (2,2)
						if ( (My_Row==(Iter_Counter+2)) && (My_Column==My_Row) ){
									Local_Mem_Address= ((Iter_Counter+2)/ LAPU_Size) * (Kernel_Size/LAPU_Size)+Trsm_index;
									Write_My_Row_Reg_Next=Local_Mem.Reg_Read(Local_Mem_Address);
								}

						// Load the next BC into Bus Registers  Row 1 and Column 1 PEs
						if (My_Row==(Iter_Counter+1)){
							Local_Mem_Address=(Global_index)*(Kernel_Size/LAPU_Size) + (Iter_Counter+1)/LAPU_Size;
							Write_My_Col_Reg_Next=Local_Mem.Reg_Read(Local_Mem_Address);
						}
						else if (My_Column==(Iter_Counter+1)){
							Local_Mem_Address=((Iter_Counter+1)/LAPU_Size) * Kernel_Size/LAPU_Size + Trsm_index;
							Write_My_Row_Reg_Next=Local_Mem.Reg_Read(Local_Mem_Address);
						}

						//Driving the bus  Row 0 and Column 0
						if (My_Column==0)
							*Write_My_Row_Bus=Write_My_Row_Reg_Curr;

						if (My_Row==0)
							*Write_My_Col_Bus=Write_My_Col_Reg_Curr;





					break;

					case 3: // MAC_and_BC

						//1-Pre_Fetch PE(Iteration_Counter+ 2,Iteration_Counter+ 2)
						//2-Prepare to BC the Column Iteration_Counter+1 and Iteration_Counter+1  (Diagonal PE does the row fetch now)
						//3-Drive the Bus for Row Iteration_Counter and  Column Iteration_Counter
						//4- perform MAC on Row Iteration_Counter-1 and  Column Iteration_Counter-1

						////Communication part *****


						if ( (Iter_Counter+2) < (Global_index* LAPU_Size) )

							if (( My_Row==((Iter_Counter+2)%LAPU_Size) ) && (My_Column==My_Row)){
										Local_Mem_Address= ((Iter_Counter+2)/ LAPU_Size) * (Kernel_Size/LAPU_Size)+Trsm_index;
										Write_My_Row_Reg_Next=Local_Mem.Reg_Read(Local_Mem_Address);
									}




						// Load the next BC into Bus Registers
						if ( (Iter_Counter+1) < (Global_index* LAPU_Size) ){

							if (My_Row==((Iter_Counter+1)%LAPU_Size)) {
								Local_Mem_Address=(Global_index)*(Kernel_Size/LAPU_Size) + (Iter_Counter+1)/LAPU_Size;
								Write_My_Col_Reg_Next=Local_Mem.Reg_Read(Local_Mem_Address);

							}

							else if  (My_Column==((Iter_Counter+1)%LAPU_Size)){
								Local_Mem_Address=((Iter_Counter+1)/LAPU_Size) * Kernel_Size/LAPU_Size + Trsm_index;
								Write_My_Row_Reg_Next=Local_Mem.Reg_Read(Local_Mem_Address);

							}

						}


						// Driving Bus
						if (My_Column==(Iter_Counter%LAPU_Size))
							*Write_My_Row_Bus=Write_My_Row_Reg_Curr;

						if (My_Row==(Iter_Counter%LAPU_Size))
							*Write_My_Col_Bus=Write_My_Col_Reg_Curr;



						//	   Computation
						ALU.Execute_MAC(*Read_My_Col_Bus, (-1)*(*Read_My_Row_Bus));
						 //else
							// Scratch_Regs_Next[0]=ALU.Execute_MAD(*Read_My_Col_Bus, (-1)*(*Read_My_Row_Bus), Scratch_Regs_Curr[0]);

					break;

					case 4: // MAC
						// Nothing left to do;

						if (Latency_Counter<(FMA_Latency-1) )
							ALU.Execute_MAC(*Read_My_Col_Bus, (-1)*(*Read_My_Row_Bus));


						else{

							if (Global_index==Trsm_index){
								Scratch_Regs_Next[0]=ALU.Execute_MAC(*Read_My_Col_Bus, (-1)*(*Read_My_Row_Bus));
							}
							else
								Scratch_Regs_Next[2]=ALU.Execute_MAC(*Read_My_Col_Bus, (-1)*(*Read_My_Row_Bus));

						}



					break;

					case 5: // End
						// Write the matrix back into the Local_Store
						if (Global_index==Trsm_index){
							Local_Mem_Address=Global_index*(Kernel_Size/LAPU_Size)+Trsm_index;
							Local_Mem.Reg_Write(Local_Mem_Address, Scratch_Regs_Curr[0]);
						}
					break;


				}

				Dump_Regs();
			break;



		}


	//if ((My_Row==My_Column) && (My_Row==0))
		//Dump_Regs();

	return Local_Mem_Address;



}


